{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections.abc import Callable\n",
    "from os.path import join\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# depending on your IDE, you might need to add datathon_eth. in front of data\n",
    "from data import DataLoader, DatasetEncoding, SimpleEncoding\n",
    "\n",
    "# depending on your IDE, you might need to add datathon_eth. in front of forecast_models\n",
    "from forecast_models import SimpleModel, TimeOLSmodel, ols_time_predictor\n",
    "\n",
    "\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    diff = y_pred - y_true\n",
    "    country_error = diff.abs().sum()\n",
    "    portfolio_country_error = diff.sum()\n",
    "    return country_error, abs(portfolio_country_error)\n",
    "\n",
    "\n",
    "def cross_validate_forecaster(\n",
    "    predictor: Callable,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    verbose=True,\n",
    "    save_path=None,\n",
    "    n_splits=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform time-series cross-validation.\n",
    "    Returns:\n",
    "      mean_abs_err, mean_port_err, mean_final_score,\n",
    "      std_abs_err,  std_port_err,  std_final_score\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    all_absolute_errors = []\n",
    "    all_portfolio_errors = []\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tscv.split(y.index), start=1):\n",
    "        train_dates = pd.to_datetime(y.index[train_idx])\n",
    "        test_dates = pd.to_datetime(y.index[test_idx])\n",
    "\n",
    "        if len(test_dates) == 0:\n",
    "            continue\n",
    "\n",
    "        y_train = y.loc[train_dates]\n",
    "        y_test = y.loc[test_dates]\n",
    "\n",
    "        X_train = X.loc[train_dates]\n",
    "        X_test = X.loc[test_dates]\n",
    "\n",
    "        y_hat = predictor(X_train, y_train, X_test)\n",
    "\n",
    "        country_err, portfolio_err = evaluate_forecast(y_test, y_hat)\n",
    "\n",
    "        # Sum of absolute errors for that fold\n",
    "        mean_fold_abs = country_err\n",
    "        mean_fold_port = portfolio_err\n",
    "\n",
    "        # Example scoring formula (your logic may differ):\n",
    "        final_fold_score = (\n",
    "            1.0 * mean_fold_abs\n",
    "            + 5.0 * mean_fold_abs\n",
    "            + 10.0 * mean_fold_port\n",
    "            + 50.0 * mean_fold_port\n",
    "        )\n",
    "        # => 6.0 * mean_fold_abs + 60.0 * mean_fold_port\n",
    "\n",
    "        all_absolute_errors.append(mean_fold_abs)\n",
    "        all_portfolio_errors.append(mean_fold_port)\n",
    "        fold_scores.append(final_fold_score)\n",
    "\n",
    "    # Final metrics across folds\n",
    "    mean_abs_err = np.mean(all_absolute_errors)\n",
    "    mean_port_err = np.mean(all_portfolio_errors)\n",
    "    mean_final_score = np.mean(fold_scores)\n",
    "\n",
    "    std_abs_err = np.std(all_absolute_errors)\n",
    "    std_port_err = np.std(all_portfolio_errors)\n",
    "    std_final_score = np.std(fold_scores)\n",
    "\n",
    "    return (\n",
    "        mean_abs_err,\n",
    "        mean_port_err,\n",
    "        mean_final_score,\n",
    "        std_abs_err,\n",
    "        std_port_err,\n",
    "        std_final_score,\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate(X: pd.DataFrame, y: pd.Series, save_path: str, my_predictor):\n",
    "    \"\"\"\n",
    "    Runs cross-validation with a given predictor.\n",
    "    Returns:\n",
    "      abs_err, port_err, score, abs_err_std, port_err_std, score_std\n",
    "    \"\"\"\n",
    "    results = cross_validate_forecaster(\n",
    "        predictor=my_predictor,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        verbose=True,\n",
    "        save_path=save_path,  # not currently used to save anything, but left for clarity\n",
    "    )\n",
    "\n",
    "    (abs_err,\n",
    "     port_err,\n",
    "     score,\n",
    "     abs_err_std,\n",
    "     port_err_std,\n",
    "     score_std) = results\n",
    "\n",
    "    return abs_err, port_err, score, abs_err_std, port_err_std, score_std\n",
    "\n",
    "\n",
    "def main(model_name: str, my_predictor, max_customers=10):\n",
    "    \"\"\"\n",
    "    Train and evaluate the models for IT and ES,\n",
    "    then store one final score (sum of ES and IT),\n",
    "    and also store the std dev of all absolute errors across both zones.\n",
    "    \"\"\"\n",
    "\n",
    "    # We'll accumulate each zone's results in memory\n",
    "    zone_final_scores = {}\n",
    "    zone_errors_dataframes = {}\n",
    "\n",
    "    for zone in [\"ES\", \"IT\"]:\n",
    "        # Inputs\n",
    "        input_path = r\"datasets2025\"\n",
    "        output_path = r\"outputs\"\n",
    "\n",
    "        # Load Datasets\n",
    "        loader = DataLoader(input_path)\n",
    "        training_set, features, example_results = loader.load_data(zone)\n",
    "\n",
    "        # Additional data\n",
    "        rollout, holidays = loader.load_additional_data(zone)\n",
    "\n",
    "        # Data Manipulation and Training\n",
    "        end_training = training_set.index.max()\n",
    "        start_forecast, end_forecast = example_results.index[0], example_results.index[-1]\n",
    "\n",
    "        dataset_encoding = DatasetEncoding(\n",
    "            training_set,\n",
    "            features,\n",
    "            rollout,\n",
    "            holidays,\n",
    "            end_training=end_training,\n",
    "            start_forecast=start_forecast,\n",
    "            end_forecast=end_forecast,\n",
    "        )\n",
    "\n",
    "        range_forecast = pd.date_range(start=start_forecast, end=end_forecast, freq=\"1H\")\n",
    "        forecast = pd.DataFrame(columns=training_set.columns, index=range_forecast)\n",
    "        forecast_step = 1\n",
    "\n",
    "        # We'll store one row per-customer\n",
    "        errors = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"abs_err\",\n",
    "                \"port_err\",\n",
    "                \"abs_err_std\",\n",
    "                \"port_err_std\",\n",
    "                # We'll add \"raw_cv_score\" and \"raw_cv_score_std\" if we want to keep them\n",
    "                \"cv_score\",\n",
    "                \"cv_score_std\",\n",
    "                \"country\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        customers = training_set.columns.values[:max_customers]\n",
    "\n",
    "        for i, costumer in enumerate(customers, start=1):\n",
    "            customer_id = int(costumer.split(\"_\")[-1])\n",
    "            print(customer_id)\n",
    "            # Progress bar\n",
    "            bar_length = 30\n",
    "            progress = int(bar_length * i / max_customers)\n",
    "            bar = \"#\" * progress + \"-\" * (bar_length - progress)\n",
    "            print(f\"\\r[{bar}] {i}/{max_customers} customers processed\", end=\"\", flush=True)\n",
    "\n",
    "            df = dataset_encoding.generate_dataset(\n",
    "                customer_id,\n",
    "                window_size=24 * 7,\n",
    "                forecast_skip=1,\n",
    "                forecast_horizon=1,\n",
    "                additional_feats=[\"mean\", \"std\", \"skew\", \"kurtosis\", \"min\", \"max\"],\n",
    "            )\n",
    "\n",
    "            # Evaluate\n",
    "            X, y = dataset_encoding.get_train_data(\n",
    "                df, customer_id, forecast_step=forecast_step, drop_nans_X=True\n",
    "            )\n",
    "\n",
    "            (\n",
    "                abs_err,\n",
    "                port_err,\n",
    "                cv_score,\n",
    "                abs_err_std,\n",
    "                port_err_std,\n",
    "                cv_score_std,\n",
    "            ) = evaluate(X, y, f\"{output_path}/{customer_id}.png\", my_predictor)\n",
    "\n",
    "            errors.loc[customer_id] = {\n",
    "                \"abs_err\": abs_err,\n",
    "                \"port_err\": port_err,\n",
    "                \"abs_err_std\": abs_err_std,\n",
    "                \"port_err_std\": port_err_std,\n",
    "                \"cv_score\": cv_score,\n",
    "                \"cv_score_std\": cv_score_std,\n",
    "                \"country\": zone,\n",
    "            }\n",
    "\n",
    "        # Now compute final \"score\" per-customer with the zone-specific weighting\n",
    "        # (Stays the same as before, purely example logic).\n",
    "        errors[\"score\"] = errors.apply(\n",
    "            lambda x: (x[\"abs_err\"] * 5 + x[\"port_err\"] * 50)\n",
    "            if x[\"country\"] == \"ES\"\n",
    "            else (x[\"abs_err\"] * 1 + x[\"port_err\"] * 10),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # Save the CSV for this zone\n",
    "        errors.to_csv(f\"{output_path}/errors_{zone}.csv\")\n",
    "\n",
    "        # Final \"average score\" across all customers for THIS zone\n",
    "        final_score_zone = float(errors[\"score\"].mean())\n",
    "        zone_final_scores[zone] = final_score_zone\n",
    "\n",
    "        # Keep the DataFrame in memory for post-processing\n",
    "        zone_errors_dataframes[zone] = errors\n",
    "\n",
    "        print(f\"\\n\\n===== ZONE: {zone} =====\")\n",
    "        print(f\"Final average score: {final_score_zone:.2f}\")\n",
    "        print(\"========================\\n\")\n",
    "\n",
    "    # -----------------------\n",
    "    # After processing both zones, we compute:\n",
    "    #  1) A single final score = sum of the ES and IT final scores\n",
    "    #  2) The overall std of all absolute errors across *both* zones\n",
    "    # -----------------------\n",
    "    final_score = zone_final_scores[\"ES\"] + zone_final_scores[\"IT\"]\n",
    "    combined_errors = pd.concat(zone_errors_dataframes.values())\n",
    "\n",
    "    # \"The standard deviation of all errors\" typically means the std of abs_err across the entire dataset\n",
    "    overall_std_abs_err = float(combined_errors[\"abs_err\"].std(ddof=1) / np.sqrt(len(combined_errors)))\n",
    "\n",
    "    # Build one single record for the JSON\n",
    "    record = {\n",
    "        \"model\": model_name,\n",
    "        # single final score (sum of zone-specific final scores)\n",
    "        \"final_score\": final_score,\n",
    "        # standard deviation of all absolute errors across ES & IT\n",
    "        \"std_abs_err\": overall_std_abs_err,\n",
    "    }\n",
    "\n",
    "    # You might also decide to store \"std of score\" or portfolio errors here.\n",
    "    # For example:\n",
    "    # record[\"std_score\"] = float(combined_errors[\"score\"].std())\n",
    "\n",
    "    # Append to results.json (as one line)\n",
    "    with open(\"results.json\", \"a\", encoding=\"utf-8\") as f:\n",
    "        json.dump(record, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    print(\"===== FINAL COMBINED =====\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Final Summed Score (ES+IT): {final_score:.2f}\")\n",
    "    print(f\"Std of all absolute errors: {overall_std_abs_err:.2f}\")\n",
    "    print(\"========================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[------------------------------] 1/100 customers processed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67615/3811735560.py:158: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  range_forecast = pd.date_range(start=start_forecast, end=end_forecast, freq=\"1H\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[------------------------------] 2/100 customers processed5\n",
      "[------------------------------] 3/100 customers processed11\n",
      "[#-----------------------------] 4/100 customers processed19\n",
      "[#-----------------------------] 5/100 customers processed30\n",
      "[#-----------------------------] 6/100 customers processed31\n",
      "[##----------------------------] 7/100 customers processed39\n",
      "[##----------------------------] 8/100 customers processed40\n",
      "[##----------------------------] 9/100 customers processed44\n",
      "[###---------------------------] 10/100 customers processed45\n",
      "[###---------------------------] 11/100 customers processed46\n",
      "[###---------------------------] 12/100 customers processed48\n",
      "[###---------------------------] 13/100 customers processed59\n",
      "[####--------------------------] 14/100 customers processed60\n",
      "[####--------------------------] 15/100 customers processed61\n",
      "[####--------------------------] 16/100 customers processed62\n",
      "[#####-------------------------] 17/100 customers processed63\n",
      "[#####-------------------------] 18/100 customers processed64\n",
      "[#####-------------------------] 19/100 customers processed66\n",
      "[######------------------------] 20/100 customers processed67\n",
      "[######------------------------] 21/100 customers processed69\n",
      "[######------------------------] 22/100 customers processed70\n",
      "[######------------------------] 23/100 customers processed72\n",
      "[#######-----------------------] 24/100 customers processed74\n",
      "[#######-----------------------] 25/100 customers processed76\n",
      "[#######-----------------------] 26/100 customers processed80\n",
      "[########----------------------] 27/100 customers processed89\n",
      "[########----------------------] 28/100 customers processed90\n",
      "[########----------------------] 29/100 customers processed92\n",
      "[#########---------------------] 30/100 customers processed93\n",
      "[#########---------------------] 31/100 customers processed94\n",
      "[#########---------------------] 32/100 customers processed96\n",
      "[#########---------------------] 33/100 customers processed97\n",
      "[##########--------------------] 34/100 customers processed98\n",
      "[##########--------------------] 35/100 customers processed100\n",
      "[##########--------------------] 36/100 customers processed104\n",
      "[###########-------------------] 37/100 customers processed107\n",
      "[###########-------------------] 38/100 customers processed109\n",
      "[###########-------------------] 39/100 customers processed114\n",
      "[############------------------] 40/100 customers processed115\n",
      "[############------------------] 41/100 customers processed117\n",
      "[############------------------] 42/100 customers processed126\n",
      "[############------------------] 43/100 customers processed127\n",
      "[#############-----------------] 44/100 customers processed129\n",
      "[#############-----------------] 45/100 customers processed130\n",
      "[#############-----------------] 46/100 customers processed140\n",
      "[##############----------------] 47/100 customers processed143\n",
      "[##############----------------] 48/100 customers processed148\n",
      "[##############----------------] 49/100 customers processed151\n",
      "[###############---------------] 50/100 customers processed154\n",
      "[###############---------------] 51/100 customers processed162\n",
      "[###############---------------] 52/100 customers processed164\n",
      "[###############---------------] 53/100 customers processed167\n",
      "[################--------------] 54/100 customers processed169\n",
      "[################--------------] 55/100 customers processed175\n",
      "[################--------------] 56/100 customers processed179\n",
      "[#################-------------] 57/100 customers processed180\n",
      "[#################-------------] 58/100 customers processed182\n",
      "[#################-------------] 59/100 customers processed183\n",
      "[##################------------] 60/100 customers processed186\n",
      "[##################------------] 61/100 customers processed188\n",
      "[##################------------] 62/100 customers processed190\n",
      "[##################------------] 63/100 customers processed199\n",
      "[###################-----------] 64/100 customers processed201\n",
      "[###################-----------] 65/100 customers processed202\n",
      "[###################-----------] 66/100 customers processed207\n",
      "[####################----------] 67/100 customers processed209\n",
      "[####################----------] 68/100 customers processed210\n",
      "[####################----------] 69/100 customers processed213\n",
      "[#####################---------] 70/100 customers processed214\n",
      "[#####################---------] 71/100 customers processed216\n",
      "[#####################---------] 72/100 customers processed225\n",
      "[#####################---------] 73/100 customers processed226\n",
      "[######################--------] 74/100 customers processed232\n",
      "[######################--------] 75/100 customers processed234\n",
      "[######################--------] 76/100 customers processed242\n",
      "[#######################-------] 77/100 customers processed244\n",
      "[#######################-------] 78/100 customers processed247\n",
      "[#######################-------] 79/100 customers processed263\n",
      "[########################------] 80/100 customers processed265\n",
      "[########################------] 81/100 customers processed266\n",
      "[########################------] 82/100 customers processed267\n",
      "[########################------] 83/100 customers processed269\n",
      "[#########################-----] 84/100 customers processed270\n",
      "[#########################-----] 85/100 customers processed273\n",
      "[#########################-----] 86/100 customers processed274\n",
      "[##########################----] 87/100 customers processed282\n",
      "[##########################----] 88/100 customers processed297\n",
      "[##########################----] 89/100 customers processed298\n",
      "[###########################---] 90/100 customers processed300\n",
      "[###########################---] 91/100 customers processed307\n",
      "[###########################---] 92/100 customers processed311\n",
      "[###########################---] 93/100 customers processed312\n",
      "[############################--] 94/100 customers processed313\n",
      "[############################--] 95/100 customers processed334\n",
      "[############################--] 96/100 customers processed335\n",
      "[#############################-] 97/100 customers processed336\n",
      "[#############################-] 98/100 customers processed\n",
      "\n",
      "===== ZONE: ES =====\n",
      "Final average score: 967.88\n",
      "========================\n",
      "\n",
      "1\n",
      "[------------------------------] 1/100 customers processed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67615/3811735560.py:158: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  range_forecast = pd.date_range(start=start_forecast, end=end_forecast, freq=\"1H\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[------------------------------] 2/100 customers processed3\n",
      "[------------------------------] 3/100 customers processed4\n",
      "[#-----------------------------] 4/100 customers processed5\n",
      "[#-----------------------------] 5/100 customers processed6\n",
      "[#-----------------------------] 6/100 customers processed7\n",
      "[##----------------------------] 7/100 customers processed8\n",
      "[##----------------------------] 8/100 customers processed13\n",
      "[##----------------------------] 9/100 customers processed14\n",
      "[###---------------------------] 10/100 customers processed15\n",
      "[###---------------------------] 11/100 customers processed16\n",
      "[###---------------------------] 12/100 customers processed17\n",
      "[###---------------------------] 13/100 customers processed19\n",
      "[####--------------------------] 14/100 customers processed22\n",
      "[####--------------------------] 15/100 customers processed23\n",
      "[####--------------------------] 16/100 customers processed24\n",
      "[#####-------------------------] 17/100 customers processed26\n",
      "[#####-------------------------] 18/100 customers processed27\n",
      "[#####-------------------------] 19/100 customers processed28\n",
      "[######------------------------] 20/100 customers processed29\n",
      "[######------------------------] 21/100 customers processed30\n",
      "[######------------------------] 22/100 customers processed31\n",
      "[######------------------------] 23/100 customers processed32\n",
      "[#######-----------------------] 24/100 customers processed33\n",
      "[#######-----------------------] 25/100 customers processed34\n",
      "[#######-----------------------] 26/100 customers processed35\n",
      "[########----------------------] 27/100 customers processed36\n",
      "[########----------------------] 28/100 customers processed37\n",
      "[########----------------------] 29/100 customers processed38\n",
      "[#########---------------------] 30/100 customers processed39\n",
      "[#########---------------------] 31/100 customers processed40\n",
      "[#########---------------------] 32/100 customers processed41\n",
      "[#########---------------------] 33/100 customers processed43\n",
      "[##########--------------------] 34/100 customers processed51\n",
      "[##########--------------------] 35/100 customers processed52\n",
      "[##########--------------------] 36/100 customers processed53\n",
      "[###########-------------------] 37/100 customers processed54\n",
      "[###########-------------------] 38/100 customers processed63\n",
      "[###########-------------------] 39/100 customers processed65\n",
      "[############------------------] 40/100 customers processed69\n",
      "[############------------------] 41/100 customers processed70\n",
      "[############------------------] 42/100 customers processed72\n",
      "[############------------------] 43/100 customers processed73\n",
      "[#############-----------------] 44/100 customers processed74\n",
      "[#############-----------------] 45/100 customers processed78\n",
      "[#############-----------------] 46/100 customers processed88\n",
      "[##############----------------] 47/100 customers processed90\n",
      "[##############----------------] 48/100 customers processed92\n",
      "[##############----------------] 49/100 customers processed93\n",
      "[###############---------------] 50/100 customers processed94\n",
      "[###############---------------] 51/100 customers processed95\n",
      "[###############---------------] 52/100 customers processed96\n",
      "[###############---------------] 53/100 customers processed97\n",
      "[################--------------] 54/100 customers processed100\n",
      "[################--------------] 55/100 customers processed101\n",
      "[################--------------] 56/100 customers processed102\n",
      "[#################-------------] 57/100 customers processed103\n",
      "[#################-------------] 58/100 customers processed104\n",
      "[#################-------------] 59/100 customers processed106\n",
      "[##################------------] 60/100 customers processed109\n",
      "[##################------------] 61/100 customers processed114\n",
      "[##################------------] 62/100 customers processed116\n",
      "[##################------------] 63/100 customers processed117\n",
      "[###################-----------] 64/100 customers processed118\n",
      "[###################-----------] 65/100 customers processed119\n",
      "[###################-----------] 66/100 customers processed120\n",
      "[####################----------] 67/100 customers processed121\n",
      "[####################----------] 68/100 customers processed123\n",
      "[####################----------] 69/100 customers processed124\n",
      "[#####################---------] 70/100 customers processed125\n",
      "[#####################---------] 71/100 customers processed126\n",
      "[#####################---------] 72/100 customers processed130\n",
      "[#####################---------] 73/100 customers processed131\n",
      "[######################--------] 74/100 customers processed134\n",
      "[######################--------] 75/100 customers processed135\n",
      "[######################--------] 76/100 customers processed137\n",
      "[#######################-------] 77/100 customers processed140\n",
      "[#######################-------] 78/100 customers processed141\n",
      "[#######################-------] 79/100 customers processed147\n",
      "[########################------] 80/100 customers processed148\n",
      "[########################------] 81/100 customers processed150\n",
      "[########################------] 82/100 customers processed156\n",
      "[########################------] 83/100 customers processed157\n",
      "[#########################-----] 84/100 customers processed159\n",
      "[#########################-----] 85/100 customers processed165\n",
      "[#########################-----] 86/100 customers processed169\n",
      "[##########################----] 87/100 customers processed171\n",
      "[##########################----] 88/100 customers processed173\n",
      "[##########################----] 89/100 customers processed176\n",
      "[###########################---] 90/100 customers processed177\n",
      "[###########################---] 91/100 customers processed180\n",
      "[###########################---] 92/100 customers processed181\n",
      "[###########################---] 93/100 customers processed182\n",
      "[############################--] 94/100 customers processed183\n",
      "[############################--] 95/100 customers processed184\n",
      "[############################--] 96/100 customers processed185\n",
      "[#############################-] 97/100 customers processed187\n",
      "[#############################-] 98/100 customers processed188\n",
      "[#############################-] 99/100 customers processed189\n",
      "[##############################] 100/100 customers processed\n",
      "\n",
      "===== ZONE: IT =====\n",
      "Final average score: 99.57\n",
      "========================\n",
      "\n",
      "===== FINAL COMBINED =====\n",
      "Model: ols_time_predictor\n",
      "Final Summed Score (ES+IT): 1067.45\n",
      "Std of all absolute errors: 10.50\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ols_time_predictor\"\n",
    "main(model_name, ols_time_predictor, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
